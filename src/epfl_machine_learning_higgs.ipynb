{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# EPFL Machine Learning Higgs\n",
    "\n",
    "## Loading and preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from helpers import load_data, one_hot_encode, standardize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_directory = '../data'\n",
    "train_dataset_path = os.path.join(data_directory, 'train.csv')\n",
    "public_test_dataset_path = os.path.join(data_directory, 'test.csv')\n",
    "\n",
    "# Loading the data\n",
    "_, Y_train_public, feature_names, X_train_public = load_data(train_dataset_path)\n",
    "ids_test_public, _, _, X_test_public = load_data(public_test_dataset_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# First we will need to notice the discrete-valued column, since this needs to be one-hot encoded\n",
    "# In our dataset, only \"PRI_jet_num\" is discrete.\n",
    "discrete_column_idxs = np.where(feature_names == \"PRI_jet_num\")[0]\n",
    "\n",
    "# Update the features by one-hot encoding the discrete ones, but only update the feature names at the end\n",
    "# They will be the same for the train and test set anyway\n",
    "X_train_public, _ = one_hot_encode(X_train_public, discrete_column_idxs, feature_names)\n",
    "X_test_public, feature_names = one_hot_encode(X_test_public, discrete_column_idxs, feature_names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(X_train_public.shape, X_test_public.shape)\n",
    "print(feature_names.shape)\n",
    "\n",
    "# We need to deal with -999 somehow (missing values)\n",
    "# We will need to add terms to deal with co-linearity somewhere (like x1*x2 instead of just x1 and x2)\n",
    "\n",
    "# We will standardize the data based on the mean and standard deviation of the public train dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
