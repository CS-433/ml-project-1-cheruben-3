{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from helpers import load_data, one_hot_encode, standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_directory = '../data'\n",
    "train_dataset_path = os.path.join(data_directory, 'train.csv')\n",
    "_, Y_train_public, feature_names, X_train_public = load_data(train_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EPSILON = 1E-4\n",
    "mask_train = np.abs(X_train_public + 999) <= EPSILON\n",
    "X_train_public[mask_train] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add polynomial features before standardization\n",
    "from helpers import build_poly\n",
    "X_train_poly = build_poly(X_train_public, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standardize both\n",
    "column_means, column_stds = standardize(X_train_public)\n",
    "X_train_public = np.nan_to_num(X_train_public, nan=0.0)\n",
    "\n",
    "column_means, column_stds = standardize(X_train_poly)\n",
    "X_train_poly = np.nan_to_num(X_train_poly, nan=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_sample = 's'\n",
    "negative_sample = 'b'\n",
    "Y_train_public = np.expand_dims((Y_train_public == positive_sample).astype(np.int32), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with polynomial features (250000, 90)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error poly: 0.26796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 14.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error nonpoly: 0.284912\n"
     ]
    }
   ],
   "source": [
    "from helpers import build_poly, train_test_split\n",
    "from implementations import reg_logistic_regression_AGDR\n",
    "from metrics import LogisticRegressionLoss\n",
    "\n",
    "print(\"Data with polynomial features\",X_train_poly.shape)\n",
    "\n",
    "cutoff = 0.5\n",
    "X_poly_train, X_poly_test, Y_poly_train, Y_poly_test = train_test_split(X_train_poly, Y_train_public, 0.5)\n",
    "w_agdr_poly, _, loss = reg_logistic_regression_AGDR( \\\n",
    "    Y_poly_train, X_poly_train, lambda_=0, \\\n",
    "    initial_w=np.zeros(shape=(X_poly_train.shape[1], 1)), \\\n",
    "    max_iters=100, gamma=0.01, return_all_losses=True)\n",
    "\n",
    "predictions = (LogisticRegressionLoss.sigmoid(X_poly_test @ w_agdr_poly) > cutoff).astype(np.int32)\n",
    "error = np.sum(np.abs(Y_poly_test - predictions)) / Y_poly_test.shape[0]\n",
    "print(f\"Mean error poly:\", error)\n",
    "\n",
    "# Without polynomial features\n",
    "X_nonpoly_train, X_nonpoly_test, Y_nonpoly_train, Y_nonpoly_test = train_test_split(X_train_public, Y_train_public, 0.5)\n",
    "w_agdr_nonpoly, _, loss = reg_logistic_regression_AGDR( \\\n",
    "    Y_nonpoly_train, X_nonpoly_train, lambda_=0, \\\n",
    "    initial_w=np.zeros(shape=(X_nonpoly_train.shape[1], 1)), \\\n",
    "    max_iters=100, gamma=0.01, return_all_losses=True)\n",
    "\n",
    "predictions = (LogisticRegressionLoss.sigmoid(X_nonpoly_test @ w_agdr_nonpoly) > cutoff).astype(np.int32)\n",
    "error = np.sum(np.abs(Y_nonpoly_test - predictions)) / Y_nonpoly_test.shape[0]\n",
    "print(f\"Mean error nonpoly:\", error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7a0f4dba35c35f3b85e157684be5454902e71fd5484e2f6a7d69f27a520207d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
